Common params
Dim1		484 # number of parameters
Dim2		200 # number of timesteps
Dim3		95008 # num nodes
num_var 1
RESERVED	0
RESERVED	0
RESERVED	0
'
%LSH-VAE parameters
Training_epochs	5002
Batch_size	8
LearningR	0.001
Latent_dim	8	# Hierarchical latent Dim1
Latent_dim_end	32 # Main latent Dim1
Loss_type	1	# 1: MSE, 2, MAE, 3: smoothL1, 4: Huber
Stretch	0
RESERVED	0
RESERVED	0
alpha		1000000
RESERVED	0
RESERVED	0
Recon_iter	1
% For shortend_dataset(GPU_RAM_OUT)
Dim2_red		200
Dim3_start      0
Dim3_end		95008
'
%LatentConditioner
num_param	1
param_dir	/images
n_epoch	20000
latent_conditioner_lr	0.0002	# Increased to learn full latent range
latent_conditioner_batch	32	# Reduced for more gradient noise (regularization)
latent_conditioner_weight_decay	1e-5	# Reduced to allow fuller range learning
latent_conditioner_dropout_rate	0.01	# High dropout to prevent overfitting on small dataset
use_spatial_attention	0	# 1=on - enable spatial attention for better features
input_type	image	#image, csvs
param_data_type .png
'
%End-to-End Training Configuration
use_e2e_training	1	# 0=disabled, 1=enabled - use end-to-end training
e2e_loss_function	MSE   #MSE, MAE, Huber, SmoothL1 - loss function for reconstruction
e2e_vae_model_path	model_save/SimulGen-VAE	# path to pre-trained VAE model
use_latent_regularization	1	# 0=disabled, 1=enabled - add latent space regularization
LC_alpha    1000000
latent_reg_weight	1   #increased from 0.001 for better latent guidance